{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence, Project 2.2\n",
    "\n",
    "The project for the machine learning part is also split into two sub projects, this is the second part.\n",
    "\n",
    "**Deadline:** 24.07.2018\n",
    "\n",
    "Submit your solution (only the ipynb file) to AI.SS18@l3s.de using the subject:\n",
    "\n",
    "```\n",
    "AI18Project2.2:  [YourNames]\n",
    "```\n",
    "\n",
    "Please be sure to provide your matriculation numbers in the email.\n",
    "\n",
    "File naming convention:\n",
    "\n",
    "**`[FirstName]_[FamilyName]_[MatriculationNumber]_project_2_2.ipynb`**\n",
    "\n",
    "Where `[FirstName]_[FamilyName]_[MatriculationNumber]` is added **per participant** in the group (max 2) and devided by a `_` if there are two group members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ophelia/anaconda3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from matplotlib import cm\n",
    "from PIL import Image\n",
    "from skimage import data, io, filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please download the CIFAR-10 dataset (Python version) from: https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_path = \"/Users/ophelia/Downloads/cifar-10-batches-py\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar_filenames(path, train=True):\n",
    "    if train:\n",
    "        return list(map(str, Path(path).glob(\"*data_batch_*\")))\n",
    "    else:\n",
    "        return list(map(str, Path(path).glob(\"*test_batch*\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "`generate_data` will yield tuples of (ndarray, int), where the ndarray either has the shape of the image `(128, 128, 3)` or `(128*128*3, 1)` if reshape is set to `True` and int is just the label with a value of 0 or 1.\n",
    "\n",
    "It will also do some rough normalization to get the mean of the values to (approx.) 0 and variance to (approx.) 1. A complete pass through the data would be necessary to do this properly, but for images the implemented method is usually fine to start out with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cifar_data(paths, reshape=True, normalize=True):\n",
    "    import pickle\n",
    "\n",
    "    for file in paths:\n",
    "        #print(file)\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "            for i in range(10000):\n",
    "                image = dict[bytes(\"data\", \"utf-8\")][i]\n",
    "                if normalize:\n",
    "                    image = (image) / 256\n",
    "                    \n",
    "                if not reshape:\n",
    "                    image = image.reshape(3, 32, 32).transpose([1, 2, 0])\n",
    "                    \n",
    "                yield image, dict[bytes(\"labels\", \"utf-8\")][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.23046875, 0.16796875, 0.1953125 , ..., 0.546875  , 0.328125  ,\n",
      "       0.28125   ]), 6)\n"
     ]
    }
   ],
   "source": [
    "data = generate_cifar_data(get_cifar_filenames(cifar_path, True))\n",
    "print(next(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[0.6171875 , 0.4375    , 0.19140625],\n",
      "        [0.62109375, 0.43359375, 0.18359375],\n",
      "        [0.64453125, 0.453125  , 0.19921875],\n",
      "        ...,\n",
      "        [0.53515625, 0.37109375, 0.140625  ],\n",
      "        [0.4921875 , 0.35546875, 0.140625  ],\n",
      "        [0.453125  , 0.33203125, 0.12890625]],\n",
      "\n",
      "       [[0.59375   , 0.4375    , 0.19921875],\n",
      "        [0.58984375, 0.4296875 , 0.15625   ],\n",
      "        [0.62109375, 0.4453125 , 0.17578125],\n",
      "        ...,\n",
      "        [0.53125   , 0.37109375, 0.12109375],\n",
      "        [0.48828125, 0.35546875, 0.125     ],\n",
      "        [0.46484375, 0.34375   , 0.1328125 ]],\n",
      "\n",
      "       [[0.58984375, 0.4296875 , 0.18359375],\n",
      "        [0.58984375, 0.42578125, 0.12890625],\n",
      "        [0.6171875 , 0.43359375, 0.140625  ],\n",
      "        ...,\n",
      "        [0.54296875, 0.3828125 , 0.1328125 ],\n",
      "        [0.5078125 , 0.37109375, 0.1328125 ],\n",
      "        [0.46875   , 0.34765625, 0.12890625]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.265625  , 0.484375  , 0.69140625],\n",
      "        [0.1640625 , 0.390625  , 0.578125  ],\n",
      "        [0.12109375, 0.34375   , 0.53515625],\n",
      "        ...,\n",
      "        [0.1484375 , 0.37890625, 0.5703125 ],\n",
      "        [0.05078125, 0.25      , 0.421875  ],\n",
      "        [0.15625   , 0.33203125, 0.49609375]],\n",
      "\n",
      "       [[0.23828125, 0.453125  , 0.65625   ],\n",
      "        [0.19140625, 0.3984375 , 0.578125  ],\n",
      "        [0.13671875, 0.33203125, 0.515625  ],\n",
      "        ...,\n",
      "        [0.1015625 , 0.3203125 , 0.5078125 ],\n",
      "        [0.11328125, 0.3203125 , 0.4921875 ],\n",
      "        [0.078125  , 0.25      , 0.41796875]],\n",
      "\n",
      "       [[0.2109375 , 0.41796875, 0.625     ],\n",
      "        [0.21875   , 0.41015625, 0.58203125],\n",
      "        [0.17578125, 0.34765625, 0.515625  ],\n",
      "        ...,\n",
      "        [0.09375   , 0.30078125, 0.484375  ],\n",
      "        [0.1328125 , 0.328125  , 0.50390625],\n",
      "        [0.08203125, 0.26171875, 0.4296875 ]]]), 3)\n"
     ]
    }
   ],
   "source": [
    "data = generate_cifar_data(get_cifar_filenames(cifar_path, False), reshape=False, normalize=True)\n",
    "print(next(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c2dc17278>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "io.imshow(next(data)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will created batches of the given data and also reshape the labels to the correct dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_batches(data, batch_size):\n",
    "    while True:\n",
    "        batch = itertools.islice(data, batch_size)\n",
    "        try:\n",
    "            examples, labels = [list(x) for x in zip(*batch)]\n",
    "        except ValueError as e:\n",
    "            #print(\"End of epoch reached:\", e)\n",
    "            break\n",
    "            \n",
    "        yield examples, np.asarray(labels).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(network, n_epochs=5, learning_rate=0.1, batch_size=32, reshape=True):\n",
    "    if reshape:\n",
    "        x = tf.placeholder(dtype=tf.float32, shape=[None, 3072], name=\"x\")\n",
    "    else:\n",
    "        x = tf.placeholder(dtype=tf.float32, shape=[None, 32, 32, 3], name=\"x\")\n",
    "\n",
    "    y = tf.placeholder(dtype=tf.int32, shape=[None, 1], name=\"y\")\n",
    "    \n",
    "    loss, optimizer, accuracy, y_pred = network(x, y, learning_rate)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            data = generate_cifar_data(get_cifar_filenames(cifar_path, True)[:2], reshape)\n",
    "            loss_value, accuracy_acc, accuracy_cnt = (0,0,0)\n",
    "            for examples, labels in iter_batches(data, batch_size):\n",
    "                _, loss_value, accuracy_value = sess.run([optimizer, loss, accuracy],\n",
    "                                                         feed_dict={x: examples,\n",
    "                                                                    y: labels})\n",
    "                accuracy_cnt += 1\n",
    "                accuracy_acc += accuracy_value\n",
    "\n",
    "            if epoch % 1 == 0:\n",
    "                print(\"Epoch {%d}, Loss: {%f}, Accuracy: {%f}\"%(epoch,loss_value,accuracy_acc / accuracy_cnt))\n",
    "                data = generate_cifar_data(get_cifar_filenames(cifar_path, False), reshape)\n",
    "                examples, labels = next(iter_batches(data, 256))\n",
    "                accuracy_value, y_pred_value = sess.run([accuracy, y_pred], feed_dict={x: examples, y: labels})\n",
    "                print(\"Test accuracy: {%f}\"%(accuracy_value))\n",
    "                #print(f\"y_pred: {y_pred_value[:10]}, y: {labels[:10]}\")\n",
    "            \n",
    "        data = generate_cifar_data(get_cifar_filenames(cifar_path, False), reshape)\n",
    "        examples, labels = next(iter_batches(data, 1024))\n",
    "        return sess.run(accuracy, feed_dict={x: examples, y: labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected\n",
    "\n",
    "Implement a Neural Network consisting of three fully connected (dense) layers with dimensions:\n",
    "* 512\n",
    "* 256\n",
    "* 10\n",
    "\n",
    "Use sigmoid for the activation function of the first two layers, use no activation function for the last layer. For the loss use cross entrtopy loss.\n",
    "\n",
    "Methods that will be useful:\n",
    "* [tf.layers.dense](https://www.tensorflow.org/api_docs/python/tf/layers/dense)\n",
    "* [tf.nn.sigmoid](https://www.tensorflow.org/api_docs/python/tf/sigmoid)\n",
    "* [tf.nn.relu](https://www.tensorflow.org/api_docs/python/tf/relu)\n",
    "* [tf.train.GradientDescentOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer)\n",
    "* [tf.losses.sparse_softmax_cross_entropy](https://www.tensorflow.org/api_docs/python/tf/losses/sparse_softmax_cross_entropy)\n",
    "* [tf.train.GradientDescentOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer)\n",
    "\n",
    "Also: Do not expect the accuracy to be good! Train and test below 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(x, y, learning_rate):\n",
    "    # Your code goes here\n",
    "    dense1 = tf.layers.dense(x, 512, activation=tf.nn.sigmoid)\n",
    "    dense2 = tf.layers.dense(dense1, 256, activation=tf.nn.sigmoid)\n",
    "    dense3 = tf.layers.dense(dense2, 10)\n",
    "    \n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=dense3)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    # Note that you do not need to feed in the softmax output into the loss,\n",
    "    # sparse_softmax_cross_entropy will already do that for you.\n",
    "    # It is here only for computing the accuracy.\n",
    "    softmax = tf.nn.softmax(dense3)\n",
    "    y_pred = tf.argmax(softmax, axis=1)\n",
    "    y_pred = tf.reshape(y_pred, (-1, 1))\n",
    "    equality = tf.equal(tf.cast(y_pred, dtype=tf.int32), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "    \n",
    "    return loss, optimizer, accuracy, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch {0}, Loss: {2.302760}, Accuracy: {0.115197}\n",
      "Test accuracy: {0.187500}\n",
      "Epoch {1}, Loss: {2.292102}, Accuracy: {0.167496}\n",
      "Test accuracy: {0.218750}\n",
      "Epoch {2}, Loss: {2.281847}, Accuracy: {0.197651}\n",
      "Test accuracy: {0.265625}\n",
      "Epoch {3}, Loss: {2.271760}, Accuracy: {0.216710}\n",
      "Test accuracy: {0.281250}\n",
      "Epoch {4}, Loss: {2.261656}, Accuracy: {0.231141}\n",
      "Test accuracy: {0.273438}\n",
      "Epoch {5}, Loss: {2.251436}, Accuracy: {0.240396}\n",
      "Test accuracy: {0.285156}\n",
      "Epoch {6}, Loss: {2.241112}, Accuracy: {0.248308}\n",
      "Test accuracy: {0.289062}\n",
      "Epoch {7}, Loss: {2.230812}, Accuracy: {0.254080}\n",
      "Test accuracy: {0.292969}\n",
      "Epoch {8}, Loss: {2.220737}, Accuracy: {0.259902}\n",
      "Test accuracy: {0.296875}\n",
      "Epoch {9}, Loss: {2.211102}, Accuracy: {0.263485}\n",
      "Test accuracy: {0.289062}\n",
      "Epoch {10}, Loss: {2.202074}, Accuracy: {0.268611}\n",
      "Test accuracy: {0.285156}\n",
      "Epoch {11}, Loss: {2.193739}, Accuracy: {0.272094}\n",
      "Test accuracy: {0.289062}\n",
      "Epoch {12}, Loss: {2.186115}, Accuracy: {0.274582}\n",
      "Test accuracy: {0.300781}\n",
      "Epoch {13}, Loss: {2.179177}, Accuracy: {0.280354}\n",
      "Test accuracy: {0.296875}\n",
      "Epoch {14}, Loss: {2.172889}, Accuracy: {0.283887}\n",
      "Test accuracy: {0.304688}\n",
      "CPU times: user 2min 23s, sys: 7.14 s, total: 2min 30s\n",
      "Wall time: 51.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30273438"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time train_network(fc, learning_rate=0.01, n_epochs=15, batch_size=128, reshape=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Connected with relu\n",
    "Implement the same network as above, but use relu as activation function.\n",
    "\n",
    "Accuracy should improve quite a bit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc2(x, y, learning_rate):\n",
    "    # Your code goes here\n",
    "    dense1 = tf.layers.dense(x, 512, activation=tf.nn.relu)\n",
    "    dense2 = tf.layers.dense(dense1, 256, activation=tf.nn.relu)\n",
    "    dense3 = tf.layers.dense(dense2, 10)\n",
    "    \n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=dense3)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    softmax = tf.nn.softmax(dense3)\n",
    "    y_pred = tf.argmax(softmax, axis=1)\n",
    "    y_pred = tf.reshape(y_pred, (-1, 1))\n",
    "    equality = tf.equal(tf.cast(y_pred, dtype=tf.int32), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "    return loss, optimizer, accuracy, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch {epoch}, Loss: {loss_value}, Accuracy: {accuracy_acc / accuracy_cnt}\n",
      "Test accuracy: {accuracy_value}\n",
      "Epoch {epoch}, Loss: {loss_value}, Accuracy: {accuracy_acc / accuracy_cnt}\n",
      "Test accuracy: {accuracy_value}\n",
      "Epoch {epoch}, Loss: {loss_value}, Accuracy: {accuracy_acc / accuracy_cnt}\n",
      "Test accuracy: {accuracy_value}\n",
      "Epoch {epoch}, Loss: {loss_value}, Accuracy: {accuracy_acc / accuracy_cnt}\n",
      "Test accuracy: {accuracy_value}\n",
      "Epoch {epoch}, Loss: {loss_value}, Accuracy: {accuracy_acc / accuracy_cnt}\n",
      "Test accuracy: {accuracy_value}\n",
      "Epoch {epoch}, Loss: {loss_value}, Accuracy: {accuracy_acc / accuracy_cnt}\n",
      "Test accuracy: {accuracy_value}\n",
      "Epoch {epoch}, Loss: {loss_value}, Accuracy: {accuracy_acc / accuracy_cnt}\n",
      "Test accuracy: {accuracy_value}\n",
      "Epoch {epoch}, Loss: {loss_value}, Accuracy: {accuracy_acc / accuracy_cnt}\n",
      "Test accuracy: {accuracy_value}\n",
      "Epoch {epoch}, Loss: {loss_value}, Accuracy: {accuracy_acc / accuracy_cnt}\n",
      "Test accuracy: {accuracy_value}\n",
      "Epoch {epoch}, Loss: {loss_value}, Accuracy: {accuracy_acc / accuracy_cnt}\n",
      "Test accuracy: {accuracy_value}\n",
      "Epoch {epoch}, Loss: {loss_value}, Accuracy: {accuracy_acc / accuracy_cnt}\n",
      "Test accuracy: {accuracy_value}\n",
      "Epoch {epoch}, Loss: {loss_value}, Accuracy: {accuracy_acc / accuracy_cnt}\n",
      "Test accuracy: {accuracy_value}\n",
      "Epoch {epoch}, Loss: {loss_value}, Accuracy: {accuracy_acc / accuracy_cnt}\n",
      "Test accuracy: {accuracy_value}\n",
      "Epoch {epoch}, Loss: {loss_value}, Accuracy: {accuracy_acc / accuracy_cnt}\n",
      "Test accuracy: {accuracy_value}\n",
      "Epoch {epoch}, Loss: {loss_value}, Accuracy: {accuracy_acc / accuracy_cnt}\n",
      "Test accuracy: {accuracy_value}\n",
      "CPU times: user 2min 23s, sys: 9.51 s, total: 2min 32s\n",
      "Wall time: 56.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40039062"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time train_network(fc2, learning_rate=0.01, n_epochs=15, batch_size=128, reshape=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "Methods that will be useful:\n",
    "* [tf.layers.max_pooling2d](https://www.tensorflow.org/api_docs/python/tf/layers/max_pooling2d)\n",
    "* [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)\n",
    "* [tf.layers.dense](https://www.tensorflow.org/api_docs/python/tf/layers/dense)\n",
    "* [tf.nn.relu](https://www.tensorflow.org/api_docs/python/tf/relu)\n",
    "* [tf.train.GradientDescentOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer)\n",
    "* [tf.train.AdamOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer#minimize)\n",
    "\n",
    "Build a network with:\n",
    "* conv, kernel size 3, filter 8, stride 1, padding same, relu\n",
    "* max pooling, pool size 3, stride 2\n",
    "* conv, kernel size 3, filter 16, stride 1, padding same, relu\n",
    "* max pooling, pool size 3, stride 2\n",
    "* flatten\n",
    "* dense, 256 neurons, relu\n",
    "* dense, 512 neurons, relu\n",
    "\n",
    "Results should be similar to fully connected with relu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(x, y, learning_rate):\n",
    "    # Your code goes here\n",
    "    conv1 = tf.layers.conv2d(x, 8, 3,strides=1,padding='same',activation=tf.nn.relu)\n",
    "    mp1 = tf.layers.max_pooling2d(conv1,3,2)\n",
    "    conv2 = tf.layers.conv2d(mp1, 16, 3,strides=1,padding='same',activation=tf.nn.relu)\n",
    "    mp2 = tf.layers.max_pooling2d(conv2,3,2)\n",
    "    flat = tf.contrib.layers.flatten(mp2)\n",
    "    dense1 = tf.layers.dense(flat, 256, activation=tf.nn.relu)\n",
    "    dense2 = tf.layers.dense(dense1, 512, activation=tf.nn.relu)\n",
    "    \n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=dense2)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    softmax = tf.nn.softmax(dense2)\n",
    "    y_pred = tf.argmax(softmax, axis=1)\n",
    "    y_pred = tf.reshape(y_pred, (-1, 1))\n",
    "    equality = tf.equal(tf.cast(y_pred, dtype=tf.int32), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "    return loss, optimizer, accuracy, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch {0}, Loss: {5.105136}, Accuracy: {0.112609}\n",
      "Test accuracy: {0.097656}\n",
      "Epoch {1}, Loss: {4.852138}, Accuracy: {0.160828}\n",
      "Test accuracy: {0.117188}\n",
      "Epoch {2}, Loss: {3.748439}, Accuracy: {0.186704}\n",
      "Test accuracy: {0.140625}\n",
      "Epoch {3}, Loss: {3.704221}, Accuracy: {0.210191}\n",
      "Test accuracy: {0.148438}\n",
      "Epoch {4}, Loss: {3.648896}, Accuracy: {0.231837}\n",
      "Test accuracy: {0.175781}\n",
      "Epoch {5}, Loss: {3.591486}, Accuracy: {0.251791}\n",
      "Test accuracy: {0.195312}\n",
      "Epoch {6}, Loss: {3.538408}, Accuracy: {0.268362}\n",
      "Test accuracy: {0.214844}\n",
      "Epoch {7}, Loss: {3.484173}, Accuracy: {0.290307}\n",
      "Test accuracy: {0.222656}\n",
      "Epoch {8}, Loss: {3.440550}, Accuracy: {0.303045}\n",
      "Test accuracy: {0.230469}\n",
      "Epoch {9}, Loss: {3.411798}, Accuracy: {0.317277}\n",
      "Test accuracy: {0.246094}\n",
      "CPU times: user 5min 21s, sys: 31.7 s, total: 5min 53s\n",
      "Wall time: 2min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2841797"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time train_network(cnn, learning_rate=0.01, n_epochs=10, batch_size=128, reshape=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN, more complex\n",
    "Build a network with:\n",
    "* conv, kernel size 4, filter 16, stride 1, padding same, relu\n",
    "* max pooling, pool size 3, stride 2\n",
    "* conv, kernel size 4, filter 32, stride 1, padding same, relu\n",
    "* max pooling, pool size 3, stride 2\n",
    "* batchnorm\n",
    "* conv, kernel size 4, filter 64, stride 1, padding same, relu\n",
    "* max pooling, pool size 3, stride 2\n",
    "* batchnorm\n",
    "* flatten\n",
    "* dense, 512 neurons, relu\n",
    "* dense, 256 neurons, relu\n",
    "\n",
    "Also: Use the Adam optimizer. (Notice that it takes a smaller learning rate compared to regular GD.)\n",
    "\n",
    "Accuracy should again improve quite a bit, but it'll also take longer to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn2(x, y, learning_rate):\n",
    "    # Your code goes here\n",
    "    conv1 = tf.layers.conv2d(x, 16, 4,strides=1,padding='same',activation=tf.nn.relu)\n",
    "    mp1 = tf.layers.max_pooling2d(conv1,3,2)\n",
    "    conv2 = tf.layers.conv2d(mp1, 32, 4,strides=1,padding='same',activation=tf.nn.relu)\n",
    "    mp2 = tf.layers.max_pooling2d(conv2,3,2)\n",
    "    bn1 = tf.layers.batch_normalization(mp2)\n",
    "    conv3 = tf.layers.conv2d(bn1, 64, 4,strides=1,padding='same',activation=tf.nn.relu)\n",
    "    mp3 = tf.layers.max_pooling2d(conv2,3,2)\n",
    "    bn2 = tf.layers.batch_normalization(mp3)\n",
    "    flat = tf.contrib.layers.flatten(bn2)\n",
    "    dense1 = tf.layers.dense(flat, 256, activation=tf.nn.relu)\n",
    "    dense2 = tf.layers.dense(dense1, 512, activation=tf.nn.relu)\n",
    "    \n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=dense2)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    softmax = tf.nn.softmax(dense2)\n",
    "    y_pred = tf.argmax(softmax, axis=1)\n",
    "    y_pred = tf.reshape(y_pred, (-1, 1))\n",
    "    equality = tf.equal(tf.cast(y_pred, dtype=tf.int32), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "    return loss, optimizer, accuracy, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch {0}, Loss: {1.723091}, Accuracy: {0.286077}\n",
      "Test accuracy: {0.355469}\n",
      "Epoch {1}, Loss: {1.607167}, Accuracy: {0.456758}\n",
      "Test accuracy: {0.464844}\n",
      "Epoch {2}, Loss: {1.427501}, Accuracy: {0.514431}\n",
      "Test accuracy: {0.453125}\n",
      "Epoch {3}, Loss: {1.248525}, Accuracy: {0.551055}\n",
      "Test accuracy: {0.515625}\n",
      "Epoch {4}, Loss: {1.079514}, Accuracy: {0.583648}\n",
      "Test accuracy: {0.519531}\n",
      "Epoch {5}, Loss: {0.916561}, Accuracy: {0.604996}\n",
      "Test accuracy: {0.531250}\n",
      "Epoch {6}, Loss: {0.790035}, Accuracy: {0.623905}\n",
      "Test accuracy: {0.585938}\n",
      "Epoch {7}, Loss: {0.691676}, Accuracy: {0.643561}\n",
      "Test accuracy: {0.613281}\n",
      "Epoch {8}, Loss: {0.616181}, Accuracy: {0.660330}\n",
      "Test accuracy: {0.617188}\n",
      "Epoch {9}, Loss: {0.540436}, Accuracy: {0.674910}\n",
      "Test accuracy: {0.640625}\n",
      "Epoch {10}, Loss: {0.465357}, Accuracy: {0.689490}\n",
      "Test accuracy: {0.640625}\n",
      "Epoch {11}, Loss: {0.415232}, Accuracy: {0.698895}\n",
      "Test accuracy: {0.636719}\n",
      "Epoch {12}, Loss: {0.365216}, Accuracy: {0.710440}\n",
      "Test accuracy: {0.660156}\n",
      "Epoch {13}, Loss: {0.334812}, Accuracy: {0.716262}\n",
      "Test accuracy: {0.648438}\n",
      "Epoch {14}, Loss: {0.303206}, Accuracy: {0.723378}\n",
      "Test accuracy: {0.648438}\n",
      "Epoch {15}, Loss: {0.295393}, Accuracy: {0.733579}\n",
      "Test accuracy: {0.652344}\n",
      "Epoch {16}, Loss: {0.276656}, Accuracy: {0.746965}\n",
      "Test accuracy: {0.644531}\n",
      "Epoch {17}, Loss: {0.257658}, Accuracy: {0.760002}\n",
      "Test accuracy: {0.640625}\n",
      "Epoch {18}, Loss: {0.243233}, Accuracy: {0.771447}\n",
      "Test accuracy: {0.625000}\n",
      "Epoch {19}, Loss: {0.224821}, Accuracy: {0.783987}\n",
      "Test accuracy: {0.609375}\n",
      "Epoch {20}, Loss: {0.206654}, Accuracy: {0.794735}\n",
      "Test accuracy: {0.605469}\n",
      "Epoch {21}, Loss: {0.175626}, Accuracy: {0.805334}\n",
      "Test accuracy: {0.613281}\n",
      "Epoch {22}, Loss: {0.154642}, Accuracy: {0.814291}\n",
      "Test accuracy: {0.597656}\n",
      "Epoch {23}, Loss: {0.140204}, Accuracy: {0.815287}\n",
      "Test accuracy: {0.582031}\n",
      "Epoch {24}, Loss: {0.170999}, Accuracy: {0.821407}\n",
      "Test accuracy: {0.582031}\n",
      "Epoch {25}, Loss: {0.125076}, Accuracy: {0.835141}\n",
      "Test accuracy: {0.597656}\n",
      "Epoch {26}, Loss: {0.075015}, Accuracy: {0.850468}\n",
      "Test accuracy: {0.593750}\n",
      "Epoch {27}, Loss: {0.053795}, Accuracy: {0.864849}\n",
      "Test accuracy: {0.605469}\n",
      "Epoch {28}, Loss: {0.036947}, Accuracy: {0.877986}\n",
      "Test accuracy: {0.617188}\n",
      "Epoch {29}, Loss: {0.070442}, Accuracy: {0.896198}\n",
      "Test accuracy: {0.625000}\n",
      "CPU times: user 32min 35s, sys: 3min 18s, total: 35min 53s\n",
      "Wall time: 2h 11min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6425781"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time train_network(cnn2, learning_rate=0.001, n_epochs=30, batch_size=128, reshape=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions / Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Set `n_epochs` to 9 for cnn2 and run it again. Describe what happens with the accuracy. What is that usually called? Is this neural network generalizing well?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change `n_epochs` to 9, the accuracy would increase, but after epoch 10, the test accuracy stoped increasing when the accuracy of train keep increasing, the gap between these 2 accuracies become larger, we call this overfitting, which mean the learned weights can fit the train data very good but perform terrible on test data, the weights are not generalized for the all data, so the neural networl is not generalizing well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Set `n_epochs` to 10 for `fc` and run it again. Describe what happens with the accuracy. What is that usually called?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If n_epochs for fc was set from 5 to 10, both train and test accuracies are increasing. In the case of 5 epochs, it is called underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
